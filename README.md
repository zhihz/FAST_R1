# FAST R1 大模型推理器

## 界面预览

![FAST R1 界面预览](ForGit/cap.png)

受到 [aider](https://github.com/Aider-AI/aider) 项目启发

FAST R1 是一个强大的大模型推理工具，它能够将复杂的任务分解为多个子任务，并通过多个专门的 AI 模型并行执行这些任务。该工具特别适合处理需要多步骤推理和执行的复杂问题。
目前支持配置siliconflow的 API KEY后直接进行多模型接力推理，支持提示语自定义。
目前支持模型如 01-ai、THUDM、Qwen、internlm 和 deepseek-ai，涵盖了siliconflow各种不同规模（如1.5B、7B、32B等）和用途（如聊天、编程、指令执行等）的语言模型。

## 技术背景与设计理念

### 双模型架构的优势
FAST R1 采用了双模型架构设计，但进行了创新性的改进：

1. **推理模型（Architect）**
   - 作为系统的"思考者"，负责任务分析和分解
   - 将复杂问题拆分为可并行执行的子任务
   - 输出结构化的 JSON 格式任务描述
   - 适合使用擅长推理和规划的大模型

2. **执行模型（Executor）**
   - 作为系统的"执行者"，负责具体任务实现
   - 可并行部署多个实例同时工作
   - 专注于单一子任务的高质量完成
   - 适合使用擅长特定领域的专业模型

### 技术创新点
1. **并行执行架构**
   ```
   用户输入
      ↓
   推理模型分析
      ↓
   JSON任务分解
      ↓
   ┌─────┬─────┬─────┐
   AI1   AI2   AI3   AI4  (并行执行)
   └─────┴─────┴─────┘
      ↓
   实时结果聚合
   ```

2. **异步流处理**
   - 采用 SSE 技术实现实时响应
   - asyncio 异步编程保证性能
   - 支持多任务并发执行
   - 实时结果流式输出

3. **智能任务规划**
   - 自动评估任务复杂度
   - 智能确定所需 AI 数量
   - 优化任务分配策略
   - 支持动态任务调整



## 主要特性

### 1. 双模型协作系统
- **推理模型**：负责分析用户需求，进行逻辑推理，并将任务分解为多个子任务
- **执行模型**：负责具体执行推理模型分配的子任务，可同时运行多个实例

### 2. 智能任务分发
- 自动将复杂任务分解为最多 5 个子任务
- 采用 JSON 格式进行任务描述和分发
- 支持并行执行多个子任务

### 3. 实时流式响应
- 支持 SSE（Server-Sent Events）实时流式输出
- 推理过程和执行结果实时显示
- 多任务并行执行状态实时更新

### 4. 用户友好界面
- 清晰的三步配置流程
- 响应式布局设计
- 支持 Markdown 格式显示
- JSON 格式美化与语法高亮
- 多任务执行结果三列布局展示

### 5. 系统提示语定制
- 支持自定义推理模型和执行模型的系统提示语
- 提供默认模板和重置功能
- 实时保存配置

## 技术栈

- **后端**：
  - FastAPI
  - Python 3.x
  - asyncio 异步编程
  - SSE 实时数据流
  - httpx 异步 HTTP 客户端

- **前端**：
  - 原生 JavaScript
  - HTML5
  - CSS3
  - Marked.js（Markdown 渲染）
  - Highlight.js（代码高亮）

## 安装要求

- Python 3.7+
- pip 包管理器
- SiliconFlow API 密钥

## 安装步骤

1. 克隆项目仓库：
```bash
git clone [repository_url]
cd FAST_R1
```

2. 安装依赖：
```bash
pip install -r requirements.txt
```

3. 启动服务器：
```bash
python main.py
```

4. 访问应用：
打开浏览器访问 `http://localhost:8000`

## 使用指南

### 1. 配置 API 密钥
在cloud.siliconflow.cn 申请密钥
- 点击"设置密钥"按钮
- 输入您的 SiliconFlow API 密钥
- 系统会自动验证密钥有效性

### 2. 选择模型
- 从下拉列表中选择推理模型
- 从下拉列表中选择执行模型
- 点击"确认选择"保存设置

### 3. 系统提示语配置（可选）
- 可以自定义推理模型的提示语
- 可以自定义执行模型的提示语
- 使用"重置"按钮恢复默认设置

### 4. 开始对话
- 在输入框中输入您的问题
- 系统会自动：
  1. 使用推理模型分析问题
  2. 将任务分解为子任务
  3. 并行执行多个子任务
  4. 实时显示执行结果

## 特色功能说明

### 智能任务分解
推理模型会将复杂任务分解为多个子任务，并以 JSON 格式输出：
```json
{
    "AIcount": "3",
    "AI1": "任务1的具体描述...",
    "AI2": "任务2的具体描述...",
    "AI3": "任务3的具体描述..."
}
```

### 并行执行
- 支持多个执行模型同时运行
- 每个子任务独立执行
- 实时显示各任务进度

### 美化显示
- 推理过程清晰展示
- JSON 格式自动美化
- 执行结果三列布局
- AI 标签醒目显示

## 安全性

- API 密钥加密存储
- 支持 HTTPS
- 用户数据本地存储
- 配置文件加密保护

## 注意事项

1. 请确保 API 密钥的安全性
2. 推理模型和执行模型的选择会影响处理效果
3. 系统提示语的设置会影响任务分解和执行的质量
4. 建议使用现代浏览器以获得最佳体验

## 常见问题

Q: 为什么需要配置 API 密钥？  
A: API 密钥用于访问 SiliconFlow 的模型服务，是使用系统的必要条件。密钥会加密存储在您的本地

Q: 如何优化任务执行效果？  
A: 可以通过调整系统提示语来优化任务分解和执行效果。

Q: 支持哪些格式的输出？  
A: 系统支持 Markdown 格式和代码高亮，可以很好地展示文本、代码和表格等内容。

## 许可证

MIT

